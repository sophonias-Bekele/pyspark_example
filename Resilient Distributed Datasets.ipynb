{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91dbb4c6",
   "metadata": {},
   "source": [
    "Resilient Distributed Datasets (RDDs) are a distributed collection of immutable JVM objects that allow you to perform calculations very quickly, and they are the backbone of Apache Spark.\n",
    "\n",
    "the dataset is distributed; it is split into chunks based on some key and distributed to executor nodes.\n",
    "\n",
    "RDDs keep track (log) of all the transformations applied to each chunk to speed up the computations and provide a fallback if things go wrong\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b401bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from pyspark.sql.session import SparkSession\n",
    "spark = SparkSession.builder.appName(\"CDSC\").getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1254ea",
   "metadata": {},
   "source": [
    "##### Creating RDDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b110eba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParallelCollectionRDD[0] at readRDDFromFile at PythonRDD.scala:274"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = sc.parallelize(\n",
    "    [\n",
    "        ('Amber', 22),\n",
    "        ('Alfred', 23),\n",
    "        ('Skye', 4),\n",
    "        ('Albert', 12),\n",
    "        ('Amber', 9)\n",
    "    ]\n",
    ")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce87666d",
   "metadata": {},
   "source": [
    "sc.textFile(..., n) specifies the number of partitions the data dataset is divided into.\n",
    "\n",
    "Spark can read from multitude of filesystems\n",
    "\n",
    "Local\n",
    "    \n",
    "        * NTFS\n",
    "        * FAT\n",
    "        * HFS+\n",
    "        \n",
    "Distributed FS\n",
    "    \n",
    "        * HDFS\n",
    "        * Cassandra\n",
    "        \n",
    "Spark can automatically work with compressed datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69358cc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/home/ictpuser/Downloads/VS14MORT.txt.gz MapPartitionsRDD[2] at textFile at NativeMethodAccessorImpl.java:0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_from_file = sc.\\\n",
    "    textFile(\n",
    "        '/home/ictpuser/Downloads/VS14MORT.txt.gz',4\n",
    ")\n",
    "data_from_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363b3a84",
   "metadata": {},
   "source": [
    "##### Schema\n",
    "\n",
    "RDDs are schema-less data structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef31966b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Ferrari', 'fast'), {'porsche': 100000}, ['spain', 'visited, 4504']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_heterogenous = sc.parallelize([\n",
    "    ('Ferrari', 'fast'),\n",
    "    {'porsche': 100000},\n",
    "    ['spain', 'visited, 4504']\n",
    "]).collect()\n",
    "data_heterogenous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4235d08c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_heterogenous[1]['porsche']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40fa331c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['                   1                                          2101  M1087 432311  4M4                2014U7CN                                    I64 238 070   24 0111I64                                                                                                                                                                           01 I64                                                                                                  01  11                                 100 601']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_from_file.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2d76be",
   "metadata": {},
   "source": [
    "#### Lambda expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a331d2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractInformation(row):\n",
    "    selected_indices = [\n",
    "        2,4,5,6,7,9,10,11,12,13,14,15,16,17,18,\n",
    "         19,21,22,23,24,25,27,28,29,30,32,33,34,\n",
    "         36,37,38,39,40,41,42,43,44,45,46,47,48,\n",
    "         49,50,51,52,53,54,55,56,58,60,61,62,63,\n",
    "         64,65,66,67,68,69,70,71,72,73,74,75,76,\n",
    "         77,78,79,81,82,83,84,85,87,89\n",
    "    ]\n",
    "    record_split = re\\\n",
    "        .compile(\n",
    "            r'([\\s]{19})([0-9]{1})([\\s]{40})([0-9\\s]{2})([0-9\\s]{1})([0-9]{1})([0-9]{2})' + \n",
    "            r'([\\s]{2})([FM]{1})([0-9]{1})([0-9]{3})([0-9\\s]{1})([0-9]{2})([0-9]{2})' + \n",
    "            r'([0-9]{2})([0-9\\s]{2})([0-9]{1})([SMWDU]{1})([0-9]{1})([\\s]{16})([0-9]{4})' +\n",
    "            r'([YNU]{1})([0-9\\s]{1})([BCOU]{1})([YNU]{1})([\\s]{34})([0-9\\s]{1})([0-9\\s]{1})' +\n",
    "            r'([A-Z0-9\\s]{4})([0-9]{3})([\\s]{1})([0-9\\s]{3})([0-9\\s]{3})([0-9\\s]{2})([\\s]{1})' + \n",
    "            r'([0-9\\s]{2})([A-Z0-9\\s]{7})([A-Z0-9\\s]{7})([A-Z0-9\\s]{7})([A-Z0-9\\s]{7})' + \n",
    "            r'([A-Z0-9\\s]{7})([A-Z0-9\\s]{7})([A-Z0-9\\s]{7})([A-Z0-9\\s]{7})([A-Z0-9\\s]{7})' + \n",
    "            r'([A-Z0-9\\s]{7})([A-Z0-9\\s]{7})([A-Z0-9\\s]{7})([A-Z0-9\\s]{7})([A-Z0-9\\s]{7})' + \n",
    "            r'([A-Z0-9\\s]{7})([A-Z0-9\\s]{7})([A-Z0-9\\s]{7})([A-Z0-9\\s]{7})([A-Z0-9\\s]{7})' + \n",
    "            r'([A-Z0-9\\s]{7})([\\s]{36})([A-Z0-9\\s]{2})([\\s]{1})([A-Z0-9\\s]{5})([A-Z0-9\\s]{5})' + \n",
    "            r'([A-Z0-9\\s]{5})([A-Z0-9\\s]{5})([A-Z0-9\\s]{5})([A-Z0-9\\s]{5})([A-Z0-9\\s]{5})' + \n",
    "            r'([A-Z0-9\\s]{5})([A-Z0-9\\s]{5})([A-Z0-9\\s]{5})([A-Z0-9\\s]{5})([A-Z0-9\\s]{5})' + \n",
    "            r'([A-Z0-9\\s]{5})([A-Z0-9\\s]{5})([A-Z0-9\\s]{5})([A-Z0-9\\s]{5})([A-Z0-9\\s]{5})' + \n",
    "            r'([A-Z0-9\\s]{5})([A-Z0-9\\s]{5})([A-Z0-9\\s]{5})([\\s]{1})([0-9\\s]{2})([0-9\\s]{1})' + \n",
    "            r'([0-9\\s]{1})([0-9\\s]{1})([0-9\\s]{1})([\\s]{33})([0-9\\s]{3})([0-9\\s]{1})([0-9\\s]{1})')\n",
    "    try:\n",
    "        rs = np.array(record_split.split(row))[selected_indices]\n",
    "    except:\n",
    "        rs = np.array(['-99'] * len(selected_indices))\n",
    "    return rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb83e2a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[5] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_from_file_conv = data_from_file.map(extractInformation)\n",
    "data_from_file_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac70fd88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['1', '  ', '2', '1', '01', 'M', '1', '087', ' ', '43', '23', '11',\n",
       "        '  ', '4', 'M', '4', '2014', 'U', '7', 'C', 'N', ' ', ' ', 'I64 ',\n",
       "        '238', '070', '   ', '24', '01', '11I64  ', '       ', '       ',\n",
       "        '       ', '       ', '       ', '       ', '       ', '       ',\n",
       "        '       ', '       ', '       ', '       ', '       ', '       ',\n",
       "        '       ', '       ', '       ', '       ', '       ', '01',\n",
       "        'I64  ', '     ', '     ', '     ', '     ', '     ', '     ',\n",
       "        '     ', '     ', '     ', '     ', '     ', '     ', '     ',\n",
       "        '     ', '     ', '     ', '     ', '     ', '     ', '01', ' ',\n",
       "        ' ', '1', '1', '100', '6'], dtype='<U40')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_from_file_conv.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb91b44",
   "metadata": {},
   "source": [
    "#### Transformation\n",
    "\n",
    "Transformations shape your dataset. These include mapping, filtering, joining, and transcoding the values in your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "afdff95c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2014, 2014, 2014, 2014, 2014, 2014, 2014, 2014, 2014, -99]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The .map(...) transformation\n",
    "data_2014 = data_from_file_conv.map(lambda row: int(row[16]))\n",
    "data_2014.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad8e749e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('2014', 2014),\n",
       " ('2014', 2014),\n",
       " ('2014', 2014),\n",
       " ('2014', 2014),\n",
       " ('2014', 2014),\n",
       " ('2014', 2014),\n",
       " ('2014', 2014),\n",
       " ('2014', 2014),\n",
       " ('2014', 2014),\n",
       " ('-99', -99)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_2014_2 = data_from_file_conv.map(\n",
    "    lambda row: (row[16], int(row[16]))\n",
    ")\n",
    "data_2014_2.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50813f09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The .filter(...) transformation\n",
    "# .filter(...) method, which allows you to select elements from your dataset that fit specified criteria. \n",
    "data_filtered = data_from_file_conv.filter(\n",
    "    lambda row: row[16 == '2014' and row[21] == '0']\n",
    ")\n",
    "\n",
    "data_filtered.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f242e9ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2014', 2015, '2014', 2015, '2014', 2015, '2014', 2015, '2014', 2015]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The .flatMap(...) transformation\n",
    "# The .flatMap(...) method works similarly to .map(...), but it returns a flattened result instead of a list. \n",
    "\n",
    "data_2014_flat = data_from_file_conv.flatMap(\n",
    "        lambda row: (row[16],\n",
    "                    int(row[16]) + 1)\n",
    ")\n",
    "data_2014_flat.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba76df3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['M', 'F', '-99']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The .distinct(...) transformation\n",
    "# This method returns a list of distinct values in a specified column. It is extremely useful if you want to get to know your dataset or validate it.\n",
    "distinct_gender = data_from_file_conv.map(\n",
    "        lambda row: row[5]).distinct()\n",
    "distinct_gender.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79f1ca78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset 2631171, sample: 263247\n"
     ]
    }
   ],
   "source": [
    "# The .sample(...) transformation\n",
    "#The .sample(...) method returns a randomized sample from the dataset.\n",
    "fraction = 0.1\n",
    "data_sample = data_from_file_conv.sample(False, fraction, 666)\n",
    "print('Original dataset {0}, sample: {1}'\\\n",
    "     .format(data_from_file_conv.count(), data_sample.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d85271d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', (1, 4)), ('a', (1, 1)), ('b', (4, '6')), ('c', (10, None))]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The .leftOuterJoin(...) transformation\n",
    "# .leftOuterJoin(...), just like in the SQL world, joins two RDDs based on the values found in both datasets, and returns records from the left RDD with records from the right one appended in places where the two RDDs match\n",
    "\n",
    "rdd1 = sc.parallelize([('a', 1), ('b', 4), ('c',10)])\n",
    "rdd2 = sc.parallelize([('a', 4), ('a', 1), ('b', '6'), ('d', 15)])\n",
    "rdd3 = rdd1.leftOuterJoin(rdd2)\n",
    "rdd3.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd1558c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', (1, 4)), ('a', (1, 1)), ('b', (4, '6'))]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd4 = rdd1.join(rdd2)\n",
    "rdd4.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e02e309",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 1)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd5 = rdd1.intersection(rdd2)\n",
    "rdd5.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7270aab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The .repartition(...) transformation\n",
    "#.leftOuterJoin(...), just like in the SQL world, joins two RDDs based on the values found in both datasets, and returns records from the left RDD with records from the right one appended in places where the two RDDs match\n",
    "rdd1 = rdd1.repartition(6)\n",
    "len(rdd1.glom().collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0d4fbd8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd1.map(lambda row: row[1]).reduce(lambda x, y: x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e3fd4c8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('b', 4), ('c', 2), ('a', 12), ('d', 5)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_key = sc.parallelize(\n",
    "    [('a', 4), ('b', 3), ('c', 2), ('a', 8), ('d', 2), ('b', 1), ('d', 3)], 4)\n",
    "data_key.reduceByKey(lambda x, y: x+y).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c8a3e9e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_key.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ec87deff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_key.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "32416d87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('a', 2), ('b', 2), ('c', 1), ('d', 2)])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_key.countByKey().items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0170b037",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_key.saveAsTextFile(\n",
    "'/home/ictpuser/Downloads/data_key.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "21ce3a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseInput(row):\n",
    "    pattern = re.compile(r'\\(\\'([a-z])\\', ([0-9])\\)')\n",
    "    row_split = pattern.split(row)\n",
    "    \n",
    "    return (row_split[1], int(row_split[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5d58f5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_key_reread = sc \\\n",
    "    .textFile(\n",
    "        '/home/ictpuser/Downloads/data_key.txt') \\\n",
    "    .map(parseInput)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "50c50490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 4), ('b', 3), ('c', 2), ('a', 8), ('d', 2), ('b', 1), ('d', 3)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_key_reread.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdb978b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
